# [Maschinelles Lernen](https://de.wikipedia.org/wiki/Maschinelles_Lernen)
+id:01KCA7E5AQEWF2ZTWKW9VNFK33

## Summary

Maschinelles Lernen (ML) entwickelt, untersucht und verwendet statistische Algorithmen, auch Lernalgorithmen genannt. Solche Algorithmen können lernen, komplizierte Probleme zu lösen, obwohl der Lösungsweg nicht einfach durch Regeln beschrieben werden kann. Dazu benötigen die Algorithmen viele Beispieldaten. Ein bekanntes Anwendungsbeispiel ist die [Bilderkennung](https://de.wikipedia.org/wiki/Bilderkennung). In der mathematischen [Statistik](https://de.wikipedia.org/wiki/Statistik) bezeichnet man dieses Fachgebiet auch als statistisches Lernen.

Ein Lernalgorithmus bildet vorgegebene Beispieldaten auf ein mathematisches Modell ab. Dabei passt der Lernalgorithmus das Modell so an, dass es von den Beispieldaten auf neue Fälle verallgemeinern kann. Dieser Vorgang wird Training genannt. Nach dem Training ist der gefundene Lösungsweg im Modell gespeichert. Er wird nicht explizit programmiert. Das trainierte Modell kann für neue Daten Vorhersagen treffen oder Empfehlungen und Entscheidungen erzeugen.

Aus dem weiten Spektrum möglicher Anwendungen seien hier genannt: [Spamfilter](https://de.wikipedia.org/wiki/Spamfilter), automatisierte [Diagnose](https://de.wikipedia.org/wiki/Diagnose)­verfahren, Erkennung von [Kreditkartenbetrug](https://de.wikipedia.org/wiki/Kreditkartenbetrug), [Aktienmarkt](https://de.wikipedia.org/wiki/Aktienmarkt)­analysen, [Klassifikation](https://de.wikipedia.org/wiki/Klassifikation) von [Nukleotidsequenz](https://de.wikipedia.org/wiki/Nukleotidsequenz)en, Sprach- und [Texterkennung](https://de.wikipedia.org/wiki/Texterkennung).

Allgemein formuliert lernt ein Lernalgorithmus beim Training aus den Beispieldaten eine Funktion, die auch für neue, nicht zuvor gelernte Dateneingaben eine korrekte Ausgabe erzeugt. Es gibt verschiedene Lernstile, die sich darin unterscheiden, woher der [Algorithmus](https://de.wikipedia.org/wiki/Algorithmus) beim Training Informationen dazu erhält, was „korrekt“ ist.

Am häufigsten wird das überwachte Lernen eingesetzt. Dabei werden Vorgaben in Form von korrekten Ausgabewerten oder Rückmeldungen zur Verfügung gestellt. Beim unüberwachten Lernen werden keine Vorgaben gemacht. Die Algorithmen durchsuchen die Beispieldaten beispielsweise nach Kriterien für die Einteilung in unterschiedliche Cluster oder nach korrelierenden Merkmalen, die zusammengefasst werden können, um die Daten zu vereinfachen. Da es keine Vorgaben gibt, können diese Algorithmen unterschiedliche Lösungen vorschlagen, die anschließend zu bewerten sind. Beim bestärkenden Lernen beobachten Lernsysteme, die als Agenten bezeichnet werden, eine Umgebung und reagieren auf sie, indem sie Aktionen ausführen. Für die Aktionen erhalten sie Belohnungen. Diese Lernsysteme entwickeln selbständig eine Strategie, um möglichst viele Belohnungen zu erhalten.

## Geschichte

Dieser Abschnitt gibt einen kurzen Überblick über wichtige Ereignisse und Meilensteine.

1943 beschreiben [Warren McCulloch](https://de.wikipedia.org/wiki/Warren_McCulloch) und [Walter Pitts](https://de.wikipedia.org/wiki/Walter_Pitts) ein Modell für ein künstliches Neuron, das später als [McCulloch-Pitts-Zelle](https://de.wikipedia.org/wiki/McCulloch-Pitts-Zelle) bekannt wird. Sie zeigen auch, dass künstliche Neuronen miteinander zu einem Netz verbunden werden können, mit dem sich praktisch jede logische oder arithmetische Funktion berechnen lassen könnte.

1957 publiziert [Frank Rosenblatt](https://de.wikipedia.org/wiki/Frank_Rosenblatt) das [Perzeptron](https://de.wikipedia.org/wiki/Perzeptron)-Modell, das aus einer einzelnen Schicht von künstlichen Neuronen besteht.

In den 1960ern werden Algorithmen für Bayessche Netze entwickelt. Bayessche Netze können beispielsweise vorhersagen, mit welcher Wahrscheinlichkeit eine bestimmte [Diagnose](https://de.wikipedia.org/wiki/Diagnose) zu den Daten eines Patienten passt.

1969 weisen [Marvin Minsky](https://de.wikipedia.org/wiki/Marvin_Minsky) und [Seymour Papert](https://de.wikipedia.org/wiki/Seymour_Papert) nach, dass man mit Netzen, die nur aus einer Schicht von künstlichen Neuronen bestehen, nicht jede gegebene Funktion berechnen kann, weil man damit keine [XOR-Verknüpfung](https://de.wikipedia.org/wiki/Kontravalenz) (exklusives Oder) modellieren kann. Für das Training mehrschichtiger Netze ist zu dieser Zeit kein funktionierendes Verfahren bekannt. Danach stagniert die Forschung an künstlichen neuronalen Netzen.

1982 beschreibt [Paul Werbos](https://de.wikipedia.org/wiki/Paul_Werbos) ein Verfahren, das das Training mehrschichtiger Netze erlaubt. Es ist heute als [Backpropagation](https://de.wikipedia.org/wiki/Backpropagation) bekannt. Es folgt ein neuer Aufschwung in der Forschung an künstlichen neuronalen Netzen.

In den 1990ern gibt es große Fortschritte durch die Entwicklung von [Support Vector Machine](https://de.wikipedia.org/wiki/Support_Vector_Machine)s (SVMs) und rekurrenten neuronalen Netzen (RNNs). Wissenschaftler beginnen mit der Entwicklung von Programmen, die große Datenmengen analysieren und aus den Ergebnissen Regeln „lernen“.

In den 2000ern wird ML zunehmend auch in der Öffentlichkeit bekannt. Die stetige Zunahme von Rechenleistung und verfügbaren Datenmengen ermöglicht weitere Fortschritte. 2001 veröffentlicht [Leo Breiman](https://de.wikipedia.org/wiki/Leo_Breiman) die Grundlagen für ein als [Random Forest](https://de.wikipedia.org/wiki/Random_Forest) bekanntes Verfahren, das eine Gruppe von Entscheidungsbäumen trainiert.

2006 beschreiben [Geoffrey Hinton](https://de.wikipedia.org/wiki/Geoffrey_Hinton) et al. eine Methode, mit der man ein neuronales Netz, das aus mehreren Schichten von künstlichen Neuronen besteht, so trainieren kann, dass es handgeschriebene Zahlen mit einer [Genauigkeit](https://de.wikipedia.org/wiki/Genauigkeit) von über 98 % erkennen kann. Bis dahin schien es unmöglich zu sein, mit solchen Netzen hohe [Genauigkeit](https://de.wikipedia.org/wiki/Genauigkeit)en bei der [Klassifikation](https://de.wikipedia.org/wiki/Klassifikation) zu erreichen. Die neue Methode wird [Deep Learning](https://de.wikipedia.org/wiki/Deep_Learning) genannt.

In den folgenden Jahren wird das [Deep Learning](https://de.wikipedia.org/wiki/Deep_Learning) weiter entwickelt. Es führt zu enormen Fortschritten in der Bild- und Textverarbeitung.

Zwischen 2009 und 2012 gewannen die rekurrenten bzw. tiefen vorwärtsgerichteten neuronalen Netze der Forschungsgruppe von [Jürgen Schmidhuber](https://de.wikipedia.org/wiki/J%C3%BCrgen_Schmidhuber) am Schweizer KI-Labor [IDSIA](https://de.wikipedia.org/wiki/Istituto_Dalle_Molle_di_Studi_sull%E2%80%99[Intelligenz](https://de.wikipedia.org/wiki/Intelligenz)a_Artificiale) eine Serie von acht internationalen Wettbewerben in den Bereichen [Mustererkennung](https://de.wikipedia.org/wiki/Mustererkennung) und maschinelles Lernen. Insbesondere gewannen ihre rekurrenten LSTM-Netze drei Wettbewerbe zur verbundenen [Handschrifterkennung](https://de.wikipedia.org/wiki/Handschrifterkennung) bei der 2009 Intl. Conf. on Document Analysis and Recognition (ICDAR) ohne eingebautes A-priori-Wissen über die drei verschiedenen zu lernenden Sprachen. Die LSTM-Netze erlernten gleichzeitige Segmentierung und Erkennung. Dies waren die ersten internationalen Wettbewerbe, die durch [Deep Learning](https://de.wikipedia.org/wiki/Deep_Learning) oder rekurrente Netze gewonnen wurden.

2017 gewinnt [AlphaGo](https://de.wikipedia.org/wiki/AlphaGo) im Go-Spiel gegen den besten Spieler der Weltrangliste.

Ebenfalls 2017 stellt ein Forscherteam von Google einen Artikel zur Transformer-Architektur vor. Diese enthält einen [Aufmerksamkeit](https://de.wikipedia.org/wiki/Aufmerksamkeit)smechanismus. Netze, die diese Architektur verwenden, lernen beim Training nicht nur, wie sie Daten verarbeiten sollen, sondern auch, auf welchen Teil einer Sequenz sie im vorgegebenen Kontext ihre [Aufmerksamkeit](https://de.wikipedia.org/wiki/Aufmerksamkeit) richten sollen. Verglichen mit den bis dahin eingesetzten Architekturen reduziert sich dadurch der Aufwand für das Training beispielsweise von [Sprachmodell](https://de.wikipedia.org/wiki/Sprachmodell)en erheblich.

2020 wird [AlphaFold](https://de.wikipedia.org/wiki/AlphaFold) in der medizinischen Fachwelt als Durchbruch in der [Proteinstrukturvorhersage](https://de.wikipedia.org/wiki/Proteinstrukturvorhersage) aufgenommen. Das Programm ist in der Lage, die 3D-Struktur von Molekülen vorherzusagen.

2022 wird der [Chatbot](https://de.wikipedia.org/wiki/Chatbot) [ChatGPT](https://de.wikipedia.org/wiki/ChatGPT) öffentlich zugänglich gemacht. Das Programm ist in der Lage, mit Nutzern über textbasierte Nachrichten und Bilder zu kommunizieren.

2024 wird [AlphaFold](https://de.wikipedia.org/wiki/AlphaFold) 3 vorgestellt. Dieses Programm ist in der Lage, sowohl die 3D-Struktur von Molekülen als auch ihre Interaktion untereinander und mit anderen Molekülen vorherzusagen.

Für Beiträge zu neuronalen Netzwerken und [Deep Learning](https://de.wikipedia.org/wiki/Deep_Learning) erhielten [Yann LeCun](https://de.wikipedia.org/wiki/Yann_LeCun), [Yoshua Bengio](https://de.wikipedia.org/wiki/Yoshua_Bengio) und [Geoffrey Hinton](https://de.wikipedia.org/wiki/Geoffrey_Hinton) 2018 den [Turing Award](https://de.wikipedia.org/wiki/Turing_Award) und Hinton zusammen mit [John Hopfield](https://de.wikipedia.org/wiki/John_Hopfield) 2024 den [Nobelpreis für Physik](https://de.wikipedia.org/wiki/Nobelpreis_f%C3%BCr_Physik).

Die Entwickler von [AlphaFold](https://de.wikipedia.org/wiki/AlphaFold), [Demis Hassabis](https://de.wikipedia.org/wiki/Demis_Hassabis) und John Jumper, wurden 2024 für die Vorhersage der komplexen Strukturen von Proteinen mit dem [Nobelpreis für Chemie](https://de.wikipedia.org/wiki/Nobelpreis_f%C3%BCr_Chemie) ausgezeichnet.

## Verwandte Fachgebiete



### Künstliche [Intelligenz](https://de.wikipedia.org/wiki/Intelligenz)

Das maschinelle Lernen ist ein Teilgebiet des Fachgebietes „Künstliche [Intelligenz](https://de.wikipedia.org/wiki/Intelligenz)“, auch KI genannt. Das Fachgebiet „Künstliche [Intelligenz](https://de.wikipedia.org/wiki/Intelligenz)“ ist ein Teilgebiet der [Informatik](https://de.wikipedia.org/wiki/Informatik) mit dem Ziel, menschliche [Intelligenz](https://de.wikipedia.org/wiki/Intelligenz) zu imitieren. Etwa ab 1980 entwickelten sich die Ziele und Methoden innerhalb des Fachbereiches KI in verschiedene Richtungen. Die meisten Forscher versuchten vorrangig, durch die Verarbeitung von bekanntem Wissen in [Expertensystem](https://de.wikipedia.org/wiki/Expertensystem)en menschliche [Intelligenz](https://de.wikipedia.org/wiki/Intelligenz) nachzubilden. Gleichzeitig untersuchte eine kleine Gruppe von Forschern, ob sich die Leistung von Computern bei Vorhersagen dadurch verbessern lässt, dass sie Wissen aus Daten lernen, die Informationen zu Erfahrungen aus dem Problemfeld enthalten. Der Bereich KI zeigte zu dieser Zeit nur wenig Interesse am Lernen aus Daten. Deshalb gründeten diese Forscher den neuen Bereich ML. Das Ziel von ML ist nicht mehr, menschliche [Intelligenz](https://de.wikipedia.org/wiki/Intelligenz) zu imitieren, sondern praktische Probleme zu lösen. Inzwischen betrachten viele Experten ML als eine Schlüsseltechnologie der KI. Die öffentliche Berichterstattung verwendet die Bezeichnung KI oft gleichbedeutend mit ML.

### [Statistik](https://de.wikipedia.org/wiki/Statistik)

ML und [Statistik](https://de.wikipedia.org/wiki/Statistik) verwenden sehr ähnliche Methoden. Die beiden Fachgebiete unterscheiden sich allerdings in ihrem Hauptziel. Viele der eingesetzten Methoden können sowohl angewendet werden, um Schlussfolgerungen zu ziehen, als auch, um Vorhersagen zu treffen. Die [Statistik](https://de.wikipedia.org/wiki/Statistik) benutzt Daten von sorgfältig ausgewählten Stichproben, um daraus Rückschlüsse zu Eigenschaften einer zu untersuchenden Gesamtmenge zu ziehen. Die Methoden in der [Statistik](https://de.wikipedia.org/wiki/Statistik) legen deshalb den Schwerpunkt darauf, statistische Modelle zu erstellen und diese genau an die gegebene Problemstellung anzupassen. Damit kann man berechnen, mit welcher Wahrscheinlichkeit gefundene Zusammenhänge echt sind und nicht durch Störungen erklärt werden können. Dieses Schließen von Daten auf (hypothetische) Modelle wird als statistische Inferenz bezeichnet. Die Methoden im ML hingegen verarbeiten große Datenmengen und lernen daraus mit allgemein formulierten Algorithmen Zusammenhänge, die verallgemeinert und für Vorhersagen benutzt werden. Auch wenn ein maschinell gelerntes Modell für ein gegebenes Problem überzeugende Vorhersageergebnisse liefert, kann es unmöglich sein, die Zusammenhänge zu überprüfen, die das Modell gelernt hat und für seine Vorhersagen verwendet.

### [Data Science](https://de.wikipedia.org/wiki/Data_Science)

ML ist ein wichtiger Baustein des interdisziplinären Wissenschaftsfeldes „[Data Science](https://de.wikipedia.org/wiki/Data_Science)“. Dieser Bereich befasst sich mit der Extraktion von Erkenntnissen, Mustern und Schlüssen sowohl aus strukturierten als auch unstrukturierten Daten.

### [Data-Mining](https://de.wikipedia.org/wiki/Data-Mining) und [Knowledge Discovery in Databases](https://de.wikipedia.org/wiki/Knowledge_Discovery_in_Databases)

ML ist eng verwandt mit „[Data-Mining](https://de.wikipedia.org/wiki/Data-Mining)“. Unter [Data-Mining](https://de.wikipedia.org/wiki/Data-Mining) versteht man die systematische Anwendung statistischer Methoden auf große Datenbestände (insbesondere „[Big Data](https://de.wikipedia.org/wiki/Big_Data)“ bzw. Massendaten) mit dem Ziel, neue Querverbindungen und Trends zu erkennen. Viele Algorithmen können für beide Zwecke verwendet werden. Algorithmen aus dem ML werden beim [Data-Mining](https://de.wikipedia.org/wiki/Data-Mining) angewendet und Methoden der [Knowledge Discovery in Databases](https://de.wikipedia.org/wiki/Knowledge_Discovery_in_Databases) können genutzt werden, um Lerndaten für ML zu produzieren oder vorzuverarbeiten.

### [Mathematische Optimierung](https://de.wikipedia.org/wiki/Mathematische_Optimierung)

Die mathematische Optimierung ist eine mathematische Grundlage des ML. Die bestmögliche Anpassung eines Modells an die Trainingsdaten ist ein Optimierungsproblem. Beispielsweise wenden einige Lernalgorithmen das [Gradientenverfahren](https://de.wikipedia.org/wiki/Gradientenverfahren) an, um Modellparameter zu optimieren. In der Theorie des computergestützten Lernens bietet das [Probably Approximately Correct Learning](https://de.wikipedia.org/wiki/Probably_Approximately_Correct_Learning) einen Rahmen für die Beschreibung des ML.

## Methoden

Die Methoden von ML können nach verschiedenen Kriterien in Kategorien eingeteilt werden.

### Repräsentation des Wissens

Das maschinelle Lernen verarbeitet Beispieldaten und leitet daraus Regeln ab. Viele Anwendungsfälle erfordern, dass die Regeln, die das Modell gelernt hat und im Einsatz verwendet, von Menschen nachvollzogen und überprüft werden können.

#### Symbolische Ansätze

Ursprünglich hatte ML das Ziel, automatisch [Expertensystem](https://de.wikipedia.org/wiki/Expertensystem)e zu erzeugen und nachzubilden, wie Menschen lernen. Der Schwerpunkt lag auf symbolischen Ansätzen. Bei symbolischen Ansätzen wird das Wissen in Form von Regeln oder logischen Formeln repräsentiert. Dadurch können Menschen die Zusammenhänge und Muster, die das System für seine Vorhersagen benutzt, leicht erkennen und überprüfen. Dabei werden aussagenlogische und prädikatenlogische Systeme unterschieden. In der [Aussagenlogik](https://de.wikipedia.org/wiki/Aussagenlogik) hat jede Aussage einen von genau zwei Wahrheitswerten. Der Wahrheitswert jeder zusammengesetzten Aussage ist eindeutig durch die Wahrheitswerte ihrer Teilaussagen bestimmt. Ein Beispiel für ein solches System ist ein [Entscheidungsbaum](https://de.wikipedia.org/wiki/Entscheidungsbaum). Bekannte Algorithmen dafür sind ID3 und sein Nachfolger [C4.5](https://de.wikipedia.org/wiki/C4.5). Die [Prädikatenlogik](https://de.wikipedia.org/wiki/Pr%C3%A4dikatenlogik) ist eine Erweiterung der [Aussagenlogik](https://de.wikipedia.org/wiki/Aussagenlogik). Sie spielt in der Konzeption und [Programmierung](https://de.wikipedia.org/wiki/Programmierung) von [Expertensystem](https://de.wikipedia.org/wiki/Expertensystem)en eine Rolle, siehe auch induktive logische [Programmierung](https://de.wikipedia.org/wiki/Programmierung).

#### Nicht-symbolische Ansätze

Später änderte ML sein Ziel dahingehend, dass alle Methoden untersucht werden sollten, die die Leistung steigern können. Dazu gehören auch nicht-symbolische Ansätze, beispielsweise künstliche neuronale Netze. Diese speichern die gelernten Regeln implizit in den Parametern des Modells. Das bedeutet, dass Menschen nicht einfach erkennen und überprüfen können, welche Zusammenhänge und Muster das System für eine Vorhersage benutzt. Der Aufwand dafür, Entscheidungen nachzuvollziehen, beispielsweise durch Untersuchungen dazu, wie das Modell auf kleine Änderungen der Eingangsdaten reagiert, kann sehr hoch sein.

### Training

Beim Training bildet ein Lernalgorithmus vorgegebene Beispieldaten auf ein mathematisches Modell ab. Nach dem Training ist der gefundene Lösungsweg im Modell gespeichert. Er wird nicht explizit programmiert. Das trainierte Modell kann für neue Daten Vorhersagen treffen oder Empfehlungen und Entscheidungen erzeugen.

Beim Training baut der Lernalgorithmus ein Modell auf und passt die Parameter so an, dass die Ergebnisse des Modells die gegebene Aufgabe möglichst gut lösen. Dabei unterscheidet man drei Hauptgruppen der Trainingsüberwachung oder des Lernstils: überwachtes Lernen (englisch supervised learning), unüberwachtes Lernen (englisch unsupervised learning) und bestärkendes Lernen (engl. reinforcement learning).

#### [Überwachtes Lernen](https://de.wikipedia.org/wiki/%C3%9Cberwachtes_Lernen)

Beim überwachten Lernen wird das Modell mit Datensätzen trainiert und validiert, die für jede Eingabe einen passenden Ausgabewert enthalten. Man bezeichnet solche Datensätze als markiert oder gelabelt. Beim Training passt der Lernalgorithmus Parameter des Modells so an, dass die Ausgaben des Modells möglichst gut mit den bekannten, richtigen Ausgaben übereinstimmen. Die Ausgaben des Modells werden also durch die vorgegebenen Ausgaben „überwacht“. Typische Anwendungsbeispiele sind [Klassifikation](https://de.wikipedia.org/wiki/Klassifikation) und Regression.

Der Lernalgorithmus baut zunächst in der Lernphase mit einem Teil der Beispieldaten, dem Trainingsdatensatz, ein statistisches Modell auf. Nach der Lernphase wird die Qualität des erzeugten Modells mit einem anderen Teil der Beispieldaten, dem Testdatensatz, überprüft. Das Ziel ist, dass das Modell auch für völlig neue Daten das geforderte Verhalten zeigt. Dazu muss sich das Modell gut an die Trainingsdaten anpassen, gleichzeitig muss eine [Überanpassung](https://de.wikipedia.org/wiki/%C3%9Cberanpassung) vermieden werden.

Es lassen sich noch einige Unterkategorien für überwachtes Lernen identifizieren, die in der Literatur häufiger erwähnt werden:

Teilüberwachtes Lernen (englisch semi-supervised learning): Der Datensatz enthält nur für einen Teil der Eingaben die dazugehörigen Ausgaben. Nun werden in der Regel zwei Algorithmen kombiniert. Im ersten Schritt teilt ein [Algorithmus](https://de.wikipedia.org/wiki/Algorithmus) für unüberwachtes Lernen die Eingaben in Cluster auf und labelt anschließend alle Eingaben eines Clusters mit dem Label anderer Datenpunkte aus demselben Cluster. Danach wird ein [Algorithmus](https://de.wikipedia.org/wiki/Algorithmus) für überwachtes Lernen eingesetzt.

Aktives Lernen (englisch active learning): Der [Algorithmus](https://de.wikipedia.org/wiki/Algorithmus) hat die Möglichkeit, für einen Teil der Eingaben die korrekten Ausgaben zu erfragen. Dabei muss der [Algorithmus](https://de.wikipedia.org/wiki/Algorithmus) die Fragen bestimmen, welche einen hohen Informationsgewinn versprechen, um die Anzahl der Fragen möglichst klein zu halten.

[Selbstüberwachtes Lernen](https://de.wikipedia.org/wiki/Selbst%C3%BCberwachtes_Lernen) (englisch self-supervised learning): Diese Methode kann wie das teilüberwachte Lernen in zwei Schritte aufgeteilt werden. Im ersten Schritt erstellt ein [Algorithmus](https://de.wikipedia.org/wiki/Algorithmus) aus einem völlig ungelabelten Datensatz einen neuen Datensatz mit Pseudolabeln. Dieser Schritt gehört eigentlich zum unüberwachten Lernen. Danach wird ein [Algorithmus](https://de.wikipedia.org/wiki/Algorithmus) für überwachtes Lernen eingesetzt.

#### [Unüberwachtes Lernen](https://de.wikipedia.org/wiki/Un%C3%BCberwachtes_Lernen)

Der [Algorithmus](https://de.wikipedia.org/wiki/Algorithmus) erzeugt für eine gegebene Menge von Eingaben ein statistisches Modell, das die Eingaben beschreibt und erkannte Kategorien und Zusammenhänge enthält und somit Vorhersagen ermöglicht. [Clustering-Verfahren](https://de.wikipedia.org/wiki/Clusteranalyse) teilen Daten in mehrere Kategorien ein, die sich durch charakteristische Muster voneinander unterscheiden. Diese Verfahren erstellen selbständig [Klassifikator](https://de.wikipedia.org/wiki/Klassifikator)en. Ein wichtiger [Algorithmus](https://de.wikipedia.org/wiki/Algorithmus) in diesem Zusammenhang ist der EM-[Algorithmus](https://de.wikipedia.org/wiki/Algorithmus), der iterativ die Parameter eines Modells so festlegt, dass es die gesehenen Daten optimal erklärt. Er legt dabei das Vorhandensein nicht beobachtbarer Kategorien zugrunde und schätzt abwechselnd die Zugehörigkeit der Daten zu einer der Kategorien und die Parameter, die die Kategorien ausmachen. Eine Anwendung des EM-[Algorithmus](https://de.wikipedia.org/wiki/Algorithmus) findet sich beispielsweise in den [Hidden Markov Model](https://de.wikipedia.org/wiki/Hidden_Markov_Model)s (HMMs). Andere Methoden des unüberwachten Lernens, z. B. die [Hauptkomponentenanalyse](https://de.wikipedia.org/wiki/Hauptkomponentenanalyse), zielen darauf ab, die beobachteten Daten in eine einfachere Repräsentation zu übersetzen, die sie trotz drastisch reduzierter Information möglichst genau wiedergibt. Ein typisches Anwendungsbeispiel ist die Vorbereitung von Datensätzen für das überwachte Lernen.

#### [Bestärkendes Lernen](https://de.wikipedia.org/wiki/Best%C3%A4rkendes_Lernen)

Beim bestärkenden Lernen führt ein [Software-Agent](https://de.wikipedia.org/wiki/Software-Agent) selbständig Aktionen in einer dynamischen Umgebung aus und erlernt durch [Versuch und Irrtum](https://de.wikipedia.org/wiki/Versuch_und_Irrtum) eine Strategie (englisch policy), die die Summe der erhaltenen Belohnungen (englisch rewards) maximiert. Aufgrund seiner Allgemeingültigkeit wird dieses Gebiet auch in vielen anderen Disziplinen untersucht, z. B. in der Spieltheorie, der [Kontrolltheorie](https://de.wikipedia.org/wiki/Kontrolltheorie), dem [Operations Research](https://de.wikipedia.org/wiki/Operations_Research), der [Informationstheorie](https://de.wikipedia.org/wiki/Informationstheorie), der simulationsbasierten Optimierung, den Multiagentensystemen, der [Schwarmintelligenz](https://de.wikipedia.org/wiki/Kollektive_Intelligenz), der [Statistik](https://de.wikipedia.org/wiki/Statistik) und den genetischen Algorithmen. Beim bestärkenden Lernen wird die Umgebung normalerweise als Markov-Entscheidungsprozess (MDP) dargestellt. Eine klassische Methode zum Lösen eines MDP ist die dynamische [Programmierung](https://de.wikipedia.org/wiki/Programmierung). Die Verstärkungslernalgorithmen unterscheiden sich von den klassischen Methoden dadurch, dass sie kein exaktes mathematisches Modell des MDP voraussetzen. Sie werden eingesetzt, wenn keine exakten Modelle bekannt sind. Ein einfaches Beispiel ist ein [Saugroboter](https://de.wikipedia.org/wiki/Staubsaugerroboter), dessen Belohnung in der Staubmenge besteht, die er in einer bestimmten Zeit aufsaugt. Anspruchsvolle Beispiele sind der Einsatz in autonomen Fahrzeugen oder als Gegner eines menschlichen Spielers in einem komplexen [Strategiespiel](https://de.wikipedia.org/wiki/Strategiespiel), siehe [AlphaGo](https://de.wikipedia.org/wiki/AlphaGo).

### Batch- und Online-Learning

Beim Batch-Learning, auch Offline-Learning genannt, werden alle Beispieldaten auf einmal eingelesen. Das System kann in dieser Zeit nicht benutzt werden und ist in der Regel Offline. Nach dem Training kann das System nicht durch neue Daten verbessert werden. Wenn neue Daten dazu gelernt werden sollen, dann ist ein vollständiger neuer Trainingslauf mit allen alten und neuen Daten erforderlich.

Beim Online-Learning, auch inkrementelles Lernen genannt, wird das System inkrementell mit kleineren Datensätzen trainiert. Das Verfahren eignet sich gut für Systeme, die sich schnell an Veränderungen anpassen müssen. Dabei müssen neue Daten genau so hochwertig sein wie alte. Wenn neue Daten beispielsweise ungeprüft von einem defekten Sensor übernommen werden, besteht die Gefahr, dass das Modell mit der Zeit schlechter wird.

### Lernen von Instanzen oder Modellen

Beim ML geht es oft darum, Vorhersagen zu treffen. Dazu muss ein System von den gelernten Daten auf unbekannte Daten verallgemeinern.

Eine einfache Methode besteht darin, dass das System direkt die Merkmale von neuen Datenpunkten mit denen der gelernten Datenpunkte vergleicht und ihre Ähnlichkeit vergleicht. Das bezeichnet man als instanzbasiertes Lernen. In der Trainingsphase lernt das System nur die Trainingsdaten. Danach berechnet es bei jeder Anfrage die Ähnlichkeit von neuen Datenpunkten mit gelernten und erzeugt aus dem [Ähnlichkeitsmaß](https://de.wikipedia.org/wiki/%C3%84hnlichkeitsanalyse) eine Antwort. Ein Beispiel ist die [Nächste-Nachbarn-[Klassifikation](https://de.wikipedia.org/wiki/Klassifikation)](https://de.wikipedia.org/wiki/N%C3%A4chste-Nachbarn-[Klassifikation](https://de.wikipedia.org/wiki/Klassifikation)).

Die andere Methode besteht darin, dass das System in der Trainingsphase ein Modell entwickelt und seine Parameter so an die Trainingsdaten anpasst, dass das Modell korrekte Verallgemeinerungen oder Vorhersagen machen kann. Das bezeichnet man als modellbasiertes Lernen.

## Daten

Das Erstellen von Datensätzen mit geeigneten Beispieldaten kann mit einem hohen Aufwand verbunden sein. Die Abbildung zum MNIST-Datensatz zeigt als Beispiel einen kleinen Ausschnitt von Beispieldaten, mit denen ML das komplizierte Problem der automatischen Erkennung von handgeschriebenen Ziffern sehr gut lösen kann.

Die Beispieldaten müssen in maschinenlesbarer Form vorliegen und Informationen über Beobachtungen oder Erfahrungen enthalten, die für das Lösen des Problems relevant und repräsentativ sind. Eine Lösung für das gegebene Problem kann nur dann korrekt gelernt werden, wenn die Beispieldaten alle relevanten Merkmale korrekt, vollständig und ohne [Stichprobenverzerrung](https://de.wikipedia.org/wiki/Stichprobenverzerrung)en erfassen.

Die Daten dürfen nur diejenigen Muster aufweisen, die das Modell zur Entscheidung heranziehen soll. Andere Muster müssen entfernt werden. Beispielsweise wurde schon beobachtet, dass ein künstliches neuronales Netz, das darauf trainiert werden sollte, Züge auf Bildern zu erkennen, tatsächlich nur auf Gleise achtete. Der Aufwand dafür, solche Fehler zu erkennen und die Ursachen zu beheben, kann sehr hoch sein.

Die meisten maschinellen Lernverfahren benötigen eine große Zahl von Beispieldaten, um ein statistisches Modell zu erzeugen, das die zu lernende Funktion hinreichend genau abbildet. Bei komplizierten Problemen lässt sich die [Genauigkeit](https://de.wikipedia.org/wiki/Genauigkeit) eher durch größere Datensätze als durch bessere Lernalgorithmen verbessern.

## Modelle

Während des Trainings erzeugt ein Lernalgorithmus ein mathematisches Modell der Trainingsdaten und passt die Modellparameter an die Trainingsdaten an. Nach dem Training kann das so erzeugte Modell neue Daten verarbeiten, um Vorhersagen zu treffen. Generative Modelle können nach dem Training auch neue Daten erzeugen, die den gelernten Daten ähneln, beispielsweise neue Texte, Bilder oder Videos.

Es gibt viele Arten von Modellen, die untersucht wurden und in solchen Systemen verwendet werden. Im Folgenden werden einige Modelle, die oft eingesetzt werden, kurz beschrieben.

### [Lineare Regression](https://de.wikipedia.org/wiki/Lineare_Regression)

Die lineare Regression ist ein statistisches Verfahren, mit dem versucht wird, eine beobachtete abhängige Variable durch eine oder mehrere unabhängige Variablen zu erklären. Bei der linearen Regression wird dabei ein lineares Modell angenommen. Bei der einfachen linearen Regression wird mithilfe zweier Parameter eine Gerade (Regressionsgerade) so durch eine [Punktwolke](https://de.wikipedia.org/wiki/Punktwolke) gelegt, dass der lineare Zusammenhang zwischen $X$ und $Y$ möglichst gut beschrieben wird.

Um eine möglichst genaue Vorhersage für die abhängige Variable zu erhalten, wird eine Kostenfunktion aufgestellt. Diese Funktion beschreibt die mittlere quadratische Abweichung, die dadurch entsteht, dass die Regressionsgerade die zu erklärende Variable nur approximiert und nicht genau darstellt. Der Lernalgorithmus minimiert die Kostenfunktion.

### [Logistische Regression](https://de.wikipedia.org/wiki/Logistische_Regression)

Die logistische Regression ist eine oft eingesetzte Methode zum Lösen von binären [Klassifikation](https://de.wikipedia.org/wiki/Klassifikation)sproblemen. Sie schätzt zunächst, mit welcher Wahrscheinlichkeit ein gegebener Datenpunkt zu einer bestimmten Klasse gehört. Danach entscheidet sie, ob die berechnete Wahrscheinlichkeit größer ist als 50 %. In diesem Fall gibt sie diese Klasse als Ergebnis aus. Andernfalls gibt sie die andere Klasse als Ergebnis aus.

Während man bei der linearen Regression die mittlere quadratische Abweichung minimiert, um die optimalen Werte für die Parameter zu erhalten, maximiert man bei der logistischen Regression die [Likelihood-Funktion](https://de.wikipedia.org/wiki/Likelihood-Funktion), um die optimalen Werte der Parameter zu erhalten. Dieses Verfahren wird als [Maximum-Likelihood-Methode](https://de.wikipedia.org/wiki/Maximum-Likelihood-Methode) bezeichnet.

### k-Means-[Algorithmus](https://de.wikipedia.org/wiki/Algorithmus)

Der k-Means-[Algorithmus](https://de.wikipedia.org/wiki/Algorithmus) ist ein Verfahren zur [[Vektor](https://de.wikipedia.org/wiki/Vektor)quantisierung](https://de.wikipedia.org/wiki/[Vektor](https://de.wikipedia.org/wiki/Vektor)quantisierung), das auch zur [Clusteranalyse](https://de.wikipedia.org/wiki/Clusteranalyse) verwendet wird. Dabei wird aus einer Menge von ähnlichen Objekten eine vorher bekannte Anzahl von k Gruppen gebildet. Der [Algorithmus](https://de.wikipedia.org/wiki/Algorithmus) ist eine der am häufigsten verwendeten Techniken zur Gruppierung von Objekten, da er schnell die Zentren der Cluster findet. Dabei bevorzugt der [Algorithmus](https://de.wikipedia.org/wiki/Algorithmus) Gruppen mit geringer Varianz und ähnlicher Größe.

In der Regel wird ein approximativer [Algorithmus](https://de.wikipedia.org/wiki/Algorithmus) verwendet, der mit zufälligen Mittelwerten aus dem Trainingsdatensatz beginnt und sich danach in mehreren Schritten einer guten Clusteraufteilung annähert. Da die Problemstellung von k abhängig ist, muss dieser Parameter vom Benutzer festgelegt werden.

### [Support Vector Machine](https://de.wikipedia.org/wiki/Support_Vector_Machine)s

Eine [Support Vector Machine](https://de.wikipedia.org/wiki/Support_Vector_Machine) dient als [Klassifikator](https://de.wikipedia.org/wiki/Klassifikator) und Regressor. Eine [Support Vector Machine](https://de.wikipedia.org/wiki/Support_Vector_Machine) unterteilt eine Menge von Objekten so in Klassen, dass um die Klassengrenzen herum ein möglichst breiter Bereich frei von Objekten bleibt; sie ist ein sogenannter Large Margin Classifier (dt. „Breiter-Rand-[Klassifikator](https://de.wikipedia.org/wiki/Klassifikator)“).

Jedes Objekt wird durch einen [Vektor](https://de.wikipedia.org/wiki/Vektor) in einem [[Vektor](https://de.wikipedia.org/wiki/Vektor)raum](https://de.wikipedia.org/wiki/[Vektor](https://de.wikipedia.org/wiki/Vektor)raum) repräsentiert. Aufgabe der [Support Vector Machine](https://de.wikipedia.org/wiki/Support_Vector_Machine) ist es, in diesen Raum eine [Hyperebene](https://de.wikipedia.org/wiki/Hyperebene) einzupassen, die als Trennfläche fungiert und die Trainingsobjekte in zwei Klassen teilt. Der Abstand derjenigen [Vektor](https://de.wikipedia.org/wiki/Vektor)en, die der [Hyperebene](https://de.wikipedia.org/wiki/Hyperebene) am nächsten liegen, wird dabei maximiert. Dieser breite, leere Rand soll später dafür sorgen, dass auch Objekte, die nicht genau den Trainingsobjekten entsprechen, möglichst zuverlässig klassifiziert werden.


Eine saubere Trennung mit einer [Hyperebene](https://de.wikipedia.org/wiki/Hyperebene) ist nur dann möglich, wenn die Objekte linear trennbar sind. Diese Bedingung ist für reale Trainingsobjektmengen im Allgemeinen nicht erfüllt. [Support Vector Machine](https://de.wikipedia.org/wiki/Support_Vector_Machine)s überführen beim Training den [[Vektor](https://de.wikipedia.org/wiki/Vektor)raum](https://de.wikipedia.org/wiki/[Vektor](https://de.wikipedia.org/wiki/Vektor)raum) und damit auch die darin befindlichen Trainingsvektoren in einen höherdimensionalen Raum, um eine nichtlineare Klassengrenze einzuziehen. In einem Raum mit genügend hoher Dimensionsanzahl – im Zweifelsfall unendlich – wird auch die verschachteltste [Vektor](https://de.wikipedia.org/wiki/Vektor)menge linear trennbar.

Die Hochtransformation ist enorm rechenlastig und die Darstellung der Trennfläche im niedrigdimensionalen Raum im Allgemeinen unwahrscheinlich komplex und damit praktisch unbrauchbar. An dieser Stelle setzt der sogenannte [Kernel-Trick](https://de.wikipedia.org/wiki/Kernel-Methode) an. Verwendet man zur Beschreibung der Trennfläche geeignete Kernelfunktionen, die im Hochdimensionalen die [Hyperebene](https://de.wikipedia.org/wiki/Hyperebene) beschreiben und trotzdem im Niedrigdimensionalen „gutartig“ bleiben, so ist es möglich, die Hin- und Rücktransformation umzusetzen, ohne sie tatsächlich rechnerisch ausführen zu müssen.

### Entscheidungsbäume

Beim Lernen von Entscheidungsbäumen wird ein [Entscheidungsbaum](https://de.wikipedia.org/wiki/Entscheidungsbaum) als Modell verwendet, um Schlussfolgerungen aus den Beobachtungen zu ziehen, die im Trainingsdatensatz enthalten sind. Gelernte Regeln werden durch Knoten und Zweige des Baums repräsentiert und Schlussfolgerungen durch seine Blätter. Ein Modell mit diskreten Ausgabewerten (in der Regel ganzen Zahlen) nennt man Klassifizierungsbaum, dabei repräsentieren die Blattknoten die Klassen und die Zweige UND-Verknüpfungen der Merkmale, die zu der Klasse führen. Ein Modell mit kontinuierlichen Ausgabewerten (in der Regel reellen Zahlen) nennt man Regressionsbaum. Der [Algorithmus](https://de.wikipedia.org/wiki/Algorithmus) wählt beim Training diejenige Reihenfolge für die Abfrage der Merkmale, bei der das Modell bei jeder Verzweigung möglichst viel Information erhält. Nach dem Training kann man das Modell auch dazu verwenden, explizit und graphisch die Regeln darzustellen, die zu einer Entscheidung führen.

Der im Bild dargestellte [Binärbaum](https://de.wikipedia.org/wiki/Bin%C3%A4rbaum) benötigt als Eingabe einen [Vektor](https://de.wikipedia.org/wiki/Vektor) mit den Merkmalen eines Apfelbaumes. Ein Apfelbaum kann beispielsweise die Merkmale alt, natürliche Sorte und reichhaltiger Boden besitzen. Beginnend mit dem Wurzelknoten werden nun die Entscheidungsregeln des Baumes auf den Eingabevektor angewendet. Gelangt man nach einer Folge ausgewerteter Regeln an ein Blatt, erhält man die Antwort auf die ursprüngliche Frage.

### [Random Forest](https://de.wikipedia.org/wiki/Random_Forest)s

Ein [Random Forest](https://de.wikipedia.org/wiki/Random_Forest) besteht aus mehreren unkorrelierten Entscheidungsbäumen. Ein [Random Forest](https://de.wikipedia.org/wiki/Random_Forest) mittelt über mehrere Entscheidungsbäume, die auf verschiedenen Teilen desselben Trainingsdatensatzes trainiert wurden. Eine große Anzahl unkorrelierter Bäume macht genauere Vorhersagen möglich als ein einzelner [Entscheidungsbaum](https://de.wikipedia.org/wiki/Entscheidungsbaum). Dadurch wird in der Regel die Leistung des endgültigen Modells erheblich gesteigert.

### Künstliche Neuronale Netze

Künstliche neuronale Netze (KNN) sind Modelle, deren Struktur von biologischen neuronalen Netzen, aus denen Tiergehirne bestehen, inspiriert wurde. Solche Modelle können aus komplexen und scheinbar zusammenhanglosen Informationen lernen. Einige erfolgreiche Anwendungen sind [Bilderkennung](https://de.wikipedia.org/wiki/Bilderkennung) und [Spracherkennung](https://de.wikipedia.org/wiki/Spracherkennung).

Ein KNN wird von Einheiten oder Knoten gebildet, die miteinander verbunden sind. Die Knoten sind künstliche Neuronen. Ein künstliches Neuron empfängt Signale von anderen Neuronen und verarbeitet sie mit einer Aktivierungsfunktion. Jedem Eingangssignal ist ein Gewicht zugeordnet, das bestimmt, welchen Einfluss das Signal auf die Aktivierungsfunktion hat. Eine einfache Aktivierungsfunktion berechnet die Summe aller gewichteten Eingangssignale und legt sie als Signal auf alle Ausgänge, wenn sie einen bestimmten Schwellenwert überschreitet. Wenn die Summe unter dem Schwellenwert liegt, erzeugt diese Aktivierungsfunktion kein Ausgangssignal. Zu Beginn stehen alle Schwellenwerte und Gewichte auf Zufallswerten. Während des Trainings werden sie an die Trainingsdaten angepasst.

In der Regel werden die Neuronen in Schichten zusammengefasst. Die Signale wandern von der ersten Schicht (der Eingabeschicht) zur letzten Schicht (der Ausgabeschicht) und durchlaufen dabei möglicherweise mehrere Zwischenschichten (versteckte Schichten). Jede Schicht kann die Signale an ihren Eingängen unterschiedlich transformieren. Ein KNN mit vielen verborgenen Schichten wird auch als tiefes neuronales Netz bezeichnet. Darauf bezieht sich auch der Begriff [Deep Learning](https://de.wikipedia.org/wiki/Deep_Learning).

Bekannte Beispiele für Architekturen, die KNN einsetzen, sind rekurrente neuronale Netze (RNN) für die Verarbeitung von Sequenzen, convolutional neural networks (CNN) für die Verarbeitung von Bild- oder Audiodaten und generative vortrainierte Transformer (GPT) für [Sprachmodell](https://de.wikipedia.org/wiki/Sprachmodell)e.

### [Generative Adversarial Networks](https://de.wikipedia.org/wiki/Generative_Adversarial_Networks)

[Generative Adversarial Networks](https://de.wikipedia.org/wiki/Generative_Adversarial_Networks) (GAN) ist die Bezeichnung für eine Klasse von maschinellen Lernverfahren, die KNN im Kontext von generativem Lernen bzw. unüberwachtem Lernen trainieren. Ein GAN besteht aus zwei KNN, einem Generator und einem Diskriminator. Zuerst wird der Diskriminator darauf trainiert, zwischen echten Trainingsdaten und vom Generator aus einer zufälligen Eingabe erzeugten Daten zu unterscheiden. Danach wird der Generator darauf trainiert, aus einer zufälligen Eingabe Daten zu erzeugen, deren Eigenschaften denen der vorher vom Diskriminator gelernten Trainingsdaten so ähnlich sind, dass der Diskriminator sie nicht von ihnen unterscheiden kann. Mit diesem Verfahren kann beispielsweise ein GAN, das mit Fotografien trainiert wurde, neue Fotografien erzeugen, die für menschliche Betrachter zumindest oberflächlich authentisch aussehen und viele realistische Merkmale aufweisen. Obwohl sie ursprünglich als generatives Modell für unüberwachtes Lernen vorgeschlagen wurden, haben sich GANs auch für teilüberwachtes Lernen, überwachtes Lernen und bestärkendes Lernen als nützlich erwiesen.

## Anforderungen

Im praktischen Einsatz ist das maschinelle Lernen oft ein wesentlicher Bestandteil eines Produktes. Die Auswahl von geeigneten Methoden und Modellen wird dann neben den Eigenschaften der Trainingsdaten auch von den Anforderungen an das Produkt eingeschränkt. Beispielsweise können für Vorhersagen zum Verbraucherverhalten, für lernende autonome Systeme oder für die Optimierung von industriellen Fertigungsketten unterschiedliche Zertifizierungen erforderlich sein.

### [Genauigkeit](https://de.wikipedia.org/wiki/Genauigkeit)

[Genauigkeit](https://de.wikipedia.org/wiki/Genauigkeit) ist die wichtigste Anforderung. Wenn die geforderte [Genauigkeit](https://de.wikipedia.org/wiki/Genauigkeit) nicht erreicht werden kann, weil beispielsweise der Aufwand für die dafür erforderliche Datenerhebung zu groß wäre, dann braucht man weitere Anforderungen nicht mehr zu analysieren.

### Transparenz und Erklärbarkeit

Wenn Transparenz gefordert wird, dann wird erwartet, dass klar ist, wo welche Daten wann verarbeitet und gelöscht werden. Erklärbarkeit liegt vor, wenn die Grundlage, auf der das Modell Entscheidungen trifft, nachvollziehbar ist. Letzteres ist beim Einsatz von Entscheidungsbäumen grundsätzlich möglich, bei tiefen neuronalen Netzen zur Zeit aber nicht. Neuronale Netze liefern zwar oft gute Ergebnisse, es gibt aber keine verständliche Erklärung dazu, wie diese Ergebnisse entstanden sind. Allerdings stößt man bei komplexen Aufgaben in der Praxis auch dann schnell an Grenzen, wenn eine vollständige Überprüfung grundsätzlich möglich wäre, beispielsweise beim Überprüfen von tiefen Entscheidungsbäumen oder bei dem Versuch, umfangreiche klassische Programme mit vielen Verzweigungen nachzuvollziehen.

Zusätzlich zu den gelernten Parametern des mathematischen Modells kann eine gründliche Analyse der Daten, die zum Training und zur Validierung verwendet wurden, Aufschluss darüber geben, welche Eigenschaften die Entscheidungen des Modells am stärksten beeinflussen. Siehe auch [Ethik der Künstlichen [Intelligenz](https://de.wikipedia.org/wiki/Intelligenz)](https://de.wikipedia.org/wiki/Ethik_der_k%C3%BCnstlichen_[Intelligenz](https://de.wikipedia.org/wiki/Intelligenz)) und [Explainable Artificial Intelligence](https://de.wikipedia.org/wiki/Explainable_Artificial_Intelligence).

### Ressourcen

Bei Ressourcen geht es in erster Linie um die Zeit und die Energie, die für das Training und die Vorhersagen benötigt werden. Bei Echtzeitanwendungen kann das Einhalten einer geforderten Antwortzeit sogar wichtiger sein als die [Genauigkeit](https://de.wikipedia.org/wiki/Genauigkeit).

### [Datenschutz](https://de.wikipedia.org/wiki/Datenschutz) und Datensicherheit

Es gibt oft eine enge Beziehung zwischen Ressourcenbedarf, [Datenschutz](https://de.wikipedia.org/wiki/Datenschutz) und Datensicherheit. Beispielsweise kann man den [Datenschutz](https://de.wikipedia.org/wiki/Datenschutz) erhöhen, indem man Daten anonymisiert und das Training auf lokalen Rechnern durchführt und nicht auf externen leistungsstärkeren Servern. Siehe auch [Ethik der Künstlichen [Intelligenz](https://de.wikipedia.org/wiki/Intelligenz)](https://de.wikipedia.org/wiki/Ethik_der_k%C3%BCnstlichen_[Intelligenz](https://de.wikipedia.org/wiki/Intelligenz)).

### Freiheit und Autonomie

Beispiel: Ein Roboter, der sehen kann, ist grundsätzlich eine mobile Kamera. Um eine permanente Überwachung des Nutzers zu verhindern, sollten neue Bilder nur lokal verarbeitet werden und kurzfristig gelöscht werden. Siehe auch [Ethik der Künstlichen [Intelligenz](https://de.wikipedia.org/wiki/Intelligenz)](https://de.wikipedia.org/wiki/Ethik_der_k%C3%BCnstlichen_[Intelligenz](https://de.wikipedia.org/wiki/Intelligenz)).

### [Robustheit](https://de.wikipedia.org/wiki/Robustheit) und [Sicherheit](https://de.wikipedia.org/wiki/Sicherheit)

[Robustheit](https://de.wikipedia.org/wiki/Robustheit) und [Sicherheit](https://de.wikipedia.org/wiki/Sicherheit) eines Systems können bewertet werden, indem man analysiert, mit welcher Wahrscheinlichkeit das System Fehler macht und wie schlimm die Folgen dieser Fehler sind.

## [Automatisiertes maschinelles Lernen](https://de.wikipedia.org/wiki/Automatisiertes_maschinelles_Lernen)

Das Ziel des automatisierten maschinellen Lernens besteht darin, möglichst viele Arbeitsschritte zu automatisieren. Dazu gehören die Auswahl eines geeigneten Modells und die Anpassung seiner Hyperparameter.

## Siehe auch

[Föderales Lernen](https://de.wikipedia.org/wiki/F%C3%B6derales_Lernen)
[Empirische Risikominimierung](https://de.wikipedia.org/wiki/Empirische_Risikominimierung)
[Transfer Learning](https://de.wikipedia.org/wiki/Transfer_Learning)

## Literatur

Andreas C. Müller, Sarah Guido: Einführung in Machine Learning mit Python. O’Reilly-Verlag, Heidelberg 2017, ISBN 978-3-96009-049-6.
[Christopher M. Bishop](https://de.wikipedia.org/wiki/Christopher_Bishop): Pattern Recognition and Machine Learning. Information Science and Statistics. Springer-Verlag, Berlin 2008, ISBN 978-0-387-31073-2.
David J. C. MacKay: Information Theory, Inference and Learning Algorithms. Cambridge University Press, Cambridge 2003, ISBN 0-521-64298-1 (Online).
Trevor Hastie, Robert Tibshirani, Jerome Friedman: The Elements of Statistical Learning. Data Mining, Inference, and Prediction. 2. Auflage. Springer-Verlag, 2008, ISBN 978-0-387-84857-0 (stanford.edu [PDF]).
Thomas Mitchell: Machine Learning. Mcgraw-Hill, London 1997, ISBN 0-07-115467-1.
D. Michie, D. J. Spiegelhalter: Machine Learning, Neural and Statistical Classification. In: Ellis Horwood Series in Artificial Intelligence. E. Horwood Verlag, New York 1994, ISBN 0-13-106360-X.
Richard O. Duda, Peter E. Hart, David G. Stork: Pattern Classification. Wiley, New York 2001, ISBN 0-471-05669-3.
David Barber: Bayesian Reasoning and Machine Learning. Cambridge University Press, Cambridge 2012, ISBN 978-0-521-51814-7.
[Arthur L. Samuel](https://de.wikipedia.org/wiki/Arthur_L._Samuel) (1959): Some studies in machine learning using the game of checkers. IBM J Res Dev 3:210–229. doi:10.1147/rd.33.0210.

Alexander L. Fradkov: Early History of Machine Learning. IFAC-PapersOnLine, Volume 53, Issue 2, 2020, Pages 1385-1390, doi:10.1016/j.ifacol.2020.12.1888.

## Weblinks


Literatur von und über Maschinelles Lernen im Katalog der Deutschen Nationalbibliothek


== Einzelnachweise ==

## References

- http://www.inference.phy.cam.ac.uk/mackay/itprnn/book.html
- http:ftp://ftp.sas.com/pub/neural/FAQ2.html#A_styles
- http:ftp://ftp.sas.com/pub/neural/FAQ.html#questions
- https://books.google.de/books?id=s7KV_VVPzzYC&pg=PA34
- https://books.google.de/books?id=34HzBQAAQBAJ&pg=PA6
- https://books.google.de/books?id=6UioCgAAQBAJ&pg=PA1
- https://books.google.de/books?id=bqIIDAAAQBAJ&pg=PT105
- https://d-nb.info/gnd/4193754-5
- https://web.stanford.edu/~hastie/ElemStatLearn/printings/ESLII_print12.pdf
- https://doi.org/10.1007/s10994-011-5242-y
- https://swb.bsz-bw.de/DB=2.104/SET=1/TTL=1/CMD?retrace=0&trm_old=&ACT=SRCHA&IKT=2999&SRT=RLV&TRM=4193754-5
- https://commons.wikimedia.org/wiki/Category:Machine_learning?uselang=de
- https://lobid.org/gnd/4193754-5
- https://doi.org/10.1038/nmeth.4642
- https://www.ibm.com/topics/machine-learning
- https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6082636/
- https://news.mit.edu/2017/explained-neural-networks-deep-learning-0414
- https://prometheus.lmu.de/gnd/4193754-5
- https://www.bigdata-ai.fraunhofer.de/de/publikationen/ml-studie.html
- https://portal.dnb.de/opac.htm?method=simpleSearch&query=4193754-5
- https://web.archive.org/web/20190623150237/http://www-bcf.usc.edu/~gareth/ISL/
- https://redirecter.toolforge.org/?url=http://www-bcf.usc.edu/~gareth/ISL/
- https://www.cs.toronto.edu/~hinton/absps/fastnc.pdf
- https://id.loc.gov/authorities/sh85079324
- https://explore.gnd.network/gnd/4193754-5
- https://web.archive.org/web/20180831075249/http://www.kurzweilai.net/how-bio-inspired-deep-learning-keeps-winning-competitions
- https://web.archive.org/web/20140321040828/http://www.iro.umontreal.ca/~bengioy/papers/ftml_book.pdf
- https://www.heise.de/developer/meldung/Deep-Learning-Turing-Award-fuer-Yoshua-Bengio-Geoffrey-Hinton-und-Yann-LeCun-4353832.html
- https://www.weltderphysik.de/thema/nobelpreis/nobelpreis-fuer-physik-2024/

## URL

https://de.wikipedia.org/wiki/Maschinelles_Lernen

